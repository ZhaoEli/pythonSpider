import csv
import uuid

from fake_useragent import UserAgent
import time
import requests
import random
import datetime
from lxml import etree
from sqlalchemy import create_engine
import pandas as pd

# from lxml.html import fromstring,tostring
'''
    äºŒçº§é™æ€é¡µé¢æŠ“å–
    
    S1ï¼šè·å–é¡µé¢pageé“¾æ¥ï¼Œå¹¶æ‹¼åˆURL
    S2ï¼šè¿›å…¥é“¾æ¥é¡µé¢è§£æé¡µé¢
    S3ï¼šè£…å¡«é¡µé¢
    
'''


class housing_Prices_Spider(object):
    def __init__(self):
        # åˆ›å»ºè¿æ¥å™¨
        self.conn = create_engine('mysql+pymysql://root:zhaoaiqq@localhost:3306/DB_HOUSE_PRICES?charset=utf8')

        # ä¸€çº§é¡µé¢çš„url
        self.one_url = 'https://hz.fang.ke.com/loupan/pg{page_number}'

        # è®¾å®šä¸€ä¸ªæµè§ˆå™¨ä»£ç†å°é©¬ç”²
        self.headers = {'User-Agent': UserAgent().chrome}

        # äºŒçº§é¡µé¢éœ€è¦æ‹¼åˆä¸€ä¸‹å‰ç¼€ï¼Œæ‰èƒ½æ­£å¸¸é“¾æ¥
        self.prefix_url = 'https://hz.fang.ke.com'
        # æ¥¼ç›˜åœ°å€
        self.re_bds_url = ".//div[@class='resblock-name']/a[@class='name ']/@href"

    def get_List(self, m_url, headers, re_bds):
        html1 = requests.get(url=m_url, headers=headers).text
        html1 = html1.replace('\n\t\t\t', '')
        parse_html = etree.HTML(html1)
        # åŸºå‡† xpath è¡¨è¾¾å¼ï¼Œurlçš„èŠ‚ç‚¹å¯¹è±¡
        # url_list = parse_html.xpath(self.re_bds_name)
        # list=url_list[0].attrib
        # print(list['href'])
        url_list = parse_html.xpath(re_bds)
        return url_list

    def get_realValue(self, parse_html, xpath_bds):
        '''
        :param parse_html:
        :param xpath_bds:
        :return:
        '''
        li = parse_html.xpath(xpath_bds)  # æŠ“å–æ•°æ®
        # å¦‚æœæŠ“å–ä¸åˆ°æ•°æ®ï¼Œliä¸ºç©ºè¡¨ï¼Œåˆ™èµ‹å€¼ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œå¦‚æœæŠ“å–åˆ°åˆ™æå–
        li = li[0].strip() if li else ''
        return li

    def sql_query(self, column_list, value_list):
        '''
        å‘æ•°æ®åº“é‡Œå–æ•°
        :param column_list: å–çš„å­—æ®µ
        :param value_list: å–å€¼
        :return: id å’Œå½“å‰çš„å­—æ®µ
        :type: dataframe
        '''
        sql = '''
        select house_id, {column} ,house_type
        from DB_HOUSE_PRICES.house_item 
        where house_name="{house_name}" and house_type="{house_type}"
        '''.format(column=','.join(column_list), house_name=value_list[0], house_type=value_list[1])
        dataframe = pd.read_sql_query(sql=sql, con=self.conn)
        return dataframe

    def write_data(self):
        pass

    def run(self, min_page_number, max_page_number):
        # æ‰“å¼€æ–‡ä»¶å†™å…¥ç«¯å£
        # filename=self.filename+'.csv'
        # f =open(filename, 'a', newline='', encoding='utf-8')
        # w = csv.writer(f,delimiter=',')
        # è®¾ç½®rebdsåŒ¹é…è§„åˆ™
        zone = ".//a[@class='resblock-location']/text()"  # æ¥¼ç›˜æ‰€å¤„æ¿å—
        name = ".//div/h2[@class='DATA-PROJECT-NAME']/text()"
        other_name = ".//div[@class='other-name']/text()"
        price = ".//div[@class='top-info ']/div[@class='price']/span[@class='price-number']/text() | .//div[@class='info-wrap']/div[@class='top-info ']/div[@class='price']/span[@class='price-unit']/text()"
        # unit=""
        # value=".//div[@class='top-info ']/div[@class='price']/span[@class='price-number'][2]/text()"
        # value_unit = ".//div[@class='top-info ']/div[@class='price']/span[@class='price-unit'][1]/text()"
        tag_item = ".//div[@class='title-wrap']/div[1]/div[@class='tags-wrap']/span[@class='tag-item sell-type-tag']/text()"
        house_type = ".//div[@class='title-wrap']/div[1]/div[@class='tags-wrap']/span[@class='tag-item house-type-tag']/text()"
        address = ".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item'][1]/span[@class='content']/text()"
        new_open_date = ".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item open-date-wrap']/div[@class='open-date']/span[@class='content']/text()"
        rooms = ".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item'][2]/span[@class='content']/span[@class='house-type-item']/text()"
        collecting_time = str(datetime.date.today())  # æ•°æ®é‡‡é›†æ—¶é—´
        feature = ".//span[@class='label-val tese-val']/text()"
        builders = ".//ul[@class='x-box'][1]/li[@class='all-row'][3]/span[@class='label-val']/text()"

        for page_number in range(min_page_number, max_page_number + 1):
            one_url = self.one_url.format(page_number=page_number)
            one_url_list = self.get_List(one_url, self.headers, self.re_bds_url)
            one_zone_list = self.get_List(one_url, self.headers, zone)

            for i in range(0, len(one_url_list)):
                # è·å–æ¥¼ç›˜é¡µé¢ä¿¡æ¯
                two_url = self.prefix_url + one_url_list[i]
                html1 = requests.get(url=two_url, headers=self.headers).text
                parse_html = etree.HTML(html1)
                t_name = self.get_realValue(parse_html, name)  # æ¥¼ç›˜å
                t_house_type = self.get_realValue(parse_html, house_type)  # æˆ¿å±‹ç±»å‹ ä½å®… å•†ç”¨ å•†ä½ä¸¤ç”¨

                # æŸ¥è¯¢æ¥¼ç›˜ä¹‹å‰æ˜¯å¦è®°å½•è¿‡
                flag = self.sql_query(column_list=['house_name', 'house_type'], value_list=[t_name, t_house_type])
                if flag.empty:
                    t_other_name = self.get_realValue(parse_html, other_name)  # åˆ«å
                    t_other_name = t_other_name.replace('åˆ«åï¼š', '')
                    # t_price= parse_html.xpath(price) #å•ä»·
                    t_sale_status = self.get_realValue(parse_html, tag_item)  # æ˜¯å¦åœ¨å”®
                    t_address = self.get_realValue(parse_html, address)  # åœ°å€
                    t_new_open_date = self.get_realValue(parse_html, new_open_date)  # æœ€æ–°å¼€ç›˜
                    if t_new_open_date == '':
                        t_new_open_date = self.get_realValue(parse_html,
                                                             ".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item'][2]/span[@class='content']/text()")
                    t_rooms = parse_html.xpath(rooms)  # å‡ å®¤
                    house_zone = one_zone_list[i].strip()
                    # è·å–"æ›´å¤š"è¯¦æƒ…é¡µ
                    html = requests.get(url=two_url + "xiangqing/", headers=self.headers).text
                    parse_html = etree.HTML(html)
                    t_feature = self.get_realValue(parse_html, feature)  # ç‰¹è‰²æè¿°ï¼šæˆç†Ÿå•†åœˆ å“ç‰Œæˆ¿ä¼ VRçœ‹æˆ¿ ç»¿åŒ–ç‡é«˜
                    t_builders = self.get_realValue(parse_html, builders)  # å¼€å‘å•†

                    # æ‹¼å­—æ®µæˆä¸€ä¸ªlistï¼Œæ–¹ä¾¿æŒ‰è¡Œå†™å…¥
                    dict = {}
                    dict.update({'house_name': t_name})
                    dict.update({'collecting_time': collecting_time})
                    dict.update({'other_name': t_other_name})
                    dict.update({'house_zone': house_zone})
                    # if len(t_price) ==4: #priceæ˜¯å•ç‹¬çš„æ•°ç»„
                    # å¦‚æœåˆæœ‰å•ä»·åˆæœ‰æ€»ä»·ï¼Œéœ€è¦é‡æ–°å¤„ç†ï¼Œæ‹†åˆ†å¼€
                    #     dict.update({'price':t_price[0]})
                    #     dict.update({'uint': t_price[1]})
                    #     dict.update({'value': t_price[2]})
                    #     dict.update({'value_uint': t_price[3]})
                    # elif len(t_price) ==2:
                    #     dict.update({'price':t_price[0]})
                    #     dict.update({'uint': t_price[1]})
                    # else: dict.update({'price':''})

                    dict.update({'sale_status': t_sale_status})
                    dict.update({'house_type': t_house_type})
                    dict.update({'address': t_address})
                    # dict.update({'new_open_date':t_new_open_date})
                    # è½¬æ¢roomsä¸ºå­—ç¬¦ä¸²
                    dict.update({'rooms': ','.join(t_rooms) if t_rooms else ''})
                    dict.update({'features': t_feature})
                    dict.update({'builders': t_builders})
                    dict.update({'url_source': two_url})  # urlåœ°å€
                    dict.update({'house_id': str(uuid.uuid1()).replace('-', '')})
                    # dataframe = pd.DataFrame(dict, index=[0])
                    dataframe=pd.DataFrame.from_dict(dict,orient='index').T
                    dataframe.to_sql('house_item', self.conn, if_exists='append', index=False)
                    print('{} â€”â€”â€”â€”å†™å…¥å®Œæˆï¼Œokï¼**é¡µé¢={}'.format(t_name, page_number))
                else:
                    print('{} â€”â€”â€”â€”å·²ç»å­˜åœ¨ï¼Œ**é¡µé¢={}ï¼Œç›´æ¥è·³è¿‡ï¼ŒçŠ¶æ€ï¼šfailedï¼'.format(t_name,page_number))
                time.sleep(random.randint(1, 2))

            print('*********ç¬¬{d}ä¸ªé¡µé¢*****over******è·å–å®Œæˆï¼'.format(d=page_number))



# ä¸»å‡½æ•°
if __name__ == '__main__':

    # éœ€è¦çˆ¬å–ç½‘é¡µçš„èŒƒå›´
    min_page_number = 28  # ä»å½“å‰é¡µå¼€å§‹é‡‡é›†
    max_page_number = 40  # ç»ˆæ­¢é¡µé¢ï¼Œé‡‡é›†æ•°æ®åŒ…æ‹¬å½“å‰é¡µã€‚ğŸ“¢

    try:
        spider = housing_Prices_Spider()
        spider.run(min_page_number, max_page_number)
    except Exception as e:
        print(e)

import csv
import uuid
from fake_useragent import UserAgent
from lxml import etree
import requests
import random
import  time
import datetime
from sqlalchemy import create_engine
import pandas as pd

# from lxml.html import fromstring,tostring
'''
    äºŒçº§é™æ€é¡µé¢æŠ“å–
    
    S1ï¼šè·å–é¡µé¢pageé“¾æ¥ï¼Œå¹¶æ‹¼åˆURL
    S2ï¼šè¿›å…¥é“¾æ¥é¡µé¢è§£æé¡µé¢
    S3ï¼šè£…å¡«é¡µé¢
    
'''


class housing_Prices_Spider(object):
    def __init__(self):
        # åˆ›å»ºè¿æ¥å™¨
        self.conn = create_engine('mysql+pymysql://root:zhaoaiqq@localhost:3306/DB_HOUSE_PRICES?charset=utf8')

        # ä¸€çº§é¡µé¢çš„url
        # self.one_url = 'https://hz.fang.ke.com/loupan/pg{page_number}'
        self.one_url ='https://hz.fang.ke.com/loupan/fuyang/pg{page_number}'
        # è®¾å®šä¸€ä¸ªæµè§ˆå™¨ä»£ç†å°é©¬ç”²
        self.headers = {'User-Agent': UserAgent().chrome}

        # äºŒçº§é¡µé¢éœ€è¦æ‹¼åˆä¸€ä¸‹å‰ç¼€ï¼Œæ‰èƒ½æ­£å¸¸é“¾æ¥
        self.prefix_url = 'https://hz.fang.ke.com'
        # æ¥¼ç›˜åœ°å€
        self.re_bds_url = ".//div[@class='resblock-name']/a[@class='name ']/@href"

    def get_List(self, m_url, headers, re_bds):
        html1 = requests.get(url=m_url, headers=headers).text
        html1 = html1.replace('\n\t\t\t', '')
        parse_html = etree.HTML(html1)
        # åŸºå‡† xpath è¡¨è¾¾å¼ï¼Œurlçš„èŠ‚ç‚¹å¯¹è±¡
        # url_list = parse_html.xpath(self.re_bds_name)
        # list=url_list[0].attrib
        # print(list['href'])
        url_list = parse_html.xpath(re_bds)
        return url_list

    def get_realValue(self, parse_html, xpath_bds):
        '''
        æ¸…æ´—æ•°æ®
        :param parse_html:
        :param xpath_bds:
        :return:
        '''
        li = parse_html.xpath(xpath_bds)  # æŠ“å–æ•°æ®
        # å¦‚æœæŠ“å–ä¸åˆ°æ•°æ®ï¼Œliä¸ºç©ºè¡¨ï¼Œåˆ™èµ‹å€¼ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œå¦‚æœæŠ“å–åˆ°åˆ™æå–
        li = li[0].strip() if li else ''
        return li.replace(' ','')

    def sql_query(self, column_list, value_list):
        '''
        å‘æ•°æ®åº“é‡Œå–æ•°
        :param column_list: å–çš„å­—æ®µ
        :param value_list: å–å€¼
        :return: id å’Œå½“å‰çš„å­—æ®µ
        :type: dataframe
        '''
        sql = '''
        select house_id, {column}
        from DB_HOUSE_PRICES.house_item 
        where house_name = "{house_name}" and house_type="{house_type}"
        '''.format(column=','.join(column_list), house_name=value_list[0], house_type=value_list[1])
        dataframe = pd.read_sql_query(sql=sql, con=self.conn)
        return dataframe

    def get_xpathRds(self):
        '''
        ç”Ÿæˆç½‘é¡µæ‰€éœ€çš„xpath
        :return: ditc
        '''
        dict={}
        dict.update({'zone':".//a[@class='resblock-location']/text()"}) # æ¥¼ç›˜æ‰€å¤„æ¿å—
        dict.update({'name':".//div/h2[@class='DATA-PROJECT-NAME']/text()"})
        dict.update({'other_name':  ".//div[@class='other-name']/text()"})
        dict.update({'price':".//div[@class='top-info ']/div[@class='price']/span[@class='price-number']/text() | .//div[@class='info-wrap']/div[@class='top-info ']/div[@class='price']/span[@class='price-unit']/text()"})# unit=""
        # value=".//div[@class='top-info ']/div[@class='price']/span[@class='price-number'][2]/text()"
        # value_unit = ".//div[@class='top-info ']/div[@class='price']/span[@class='price-unit'][1]/text()"
        dict.update({'tag_item':".//div[@class='title-wrap']/div[1]/div[@class='tags-wrap']/span[@class='tag-item sell-type-tag']/text()"})
        dict.update({'house_type':".//div[@class='title-wrap']/div[1]/div[@class='tags-wrap']/span[@class='tag-item house-type-tag']/text()"})
        dict.update({'address':".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item'][1]/span[@class='content']/text()"})
        dict.update({'new_open_date':".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item open-date-wrap']/div[@class='open-date']/span[@class='content']/text()"})
        dict.update({'rooms' : ".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item'][2]/span[@class='content']/span[@class='house-type-item']/text()"})
        dict.update({'collecting_time' : str(datetime.date.today()) }) # æ•°æ®é‡‡é›†æ—¶é—´
        dict.update({'feature' :".//span[@class='label-val tese-val']/text()"})
        dict.update({'builders' :".//ul[@class='x-box'][1]/li[@class='all-row'][3]/span[@class='label-val']/text()"})
        return dict
    def get_xpathRds_info_page(self):
        dict={}
        # dict.update({'property_type':".//ul[@class='x-box'][1]/li[1]/span[@class='label-val']/text()"})#'ç‰©ä¸šç±»å‹',
        dict.update({'refer_price':".//ul[@class='x-box'][1]/li[2]/span[@class='label-val']/span/text()"})#'å‚è€ƒä»·æ ¼',
        # house_area = ''          # 'å¹³æ–¹æ•°,å•ä½ã¡',
        # open_date            #'æœ€è¿‘å¼€ç›˜',
        dict.update({'place':".//span[@class='label-val']/a/text()"})# 'åŒºåŸŸ',
        dict.update({'address':".//ul[@class='x-box'][1]/li[@class='all-row'][1]/span[@class='label-val']/text()"})              # 'åœ°å€',
        dict.update({'building_type':".//ul[@class='x-box'][2]/li[1]/span[@class='label-val']/text()"})       #'æˆ¿äº§ç±»å‹',
        dict.update({'zhandi_area' :".//ul[@class='x-box'][2]/li[3]/span[@class='label-val']/text()"})       #'å åœ°é¢ç§¯',
        dict.update({'quyu_area':".//ul[@class='x-box'][2]/li[5]/span[@class='label-val']/text()"})       #'åŒºåŸŸé¢ç§¯',
        dict.update({'blocks'   :".//ul[@class='x-box'][2]/li[7]/span[@class='label-val']/text()"})            #'è§„åˆ’æˆ·æ•°',
        dict.update({'years_limit'  :".//ul[@class='x-box'][2]/li[@class='all-row'][1]/span[@class='label-val'][1]/text()"})        #'äº§æƒå¹´é™',
        dict.update({'recently_handed_over':".//ul[@class='x-box'][2]/li[@class='all-row'][3]/span[@class='label-val']/text()"}) #'æœ€è¿‘äº¤æˆ¿',
        dict.update({'greening_rate'    :".//ul[@class='x-box'][2]/li[2]/span[@class='label-val']/text()"})    #' ç»¿åŒ–ç‡',
        dict.update({'volume_rate'     :   ".//ul[@class='x-box'][2]/li[4]/span[@class='label-val']/text()"})  #'å®¹ç§¯ç‡',
        dict.update({'property_type' :".//ul[@class='x-box'][2]/li[6]/span[@class='label-val']/text()"})      #'ç‰©ä¸šè´¹',
        dict.update({'water_supply_method':".//ul[@class='x-box'][3]/li[5]/span[@class='label-val']/text()"})  #'ä¾›æ°´æ–¹å¼',
        dict.update({'property_costs':".//ul[@class='x-box'][3]/li[3]/span[@class='label-val']/text()"}) # ç‰©ä¸šè´¹
        dict.update({'parking_numbers' :".//ul[@class='x-box'][3]/li[7]/span[@class='label-val']/text()"})     #'è½¦ä½',
        dict.update({'parking_ratio'  :".//ul[@class='x-box'][3]/li[2]/span[@class='label-val']/text()"})      #'è½¦ä½é…æ¯”',
        dict.update({'heating_method'  :".//ul[@class='x-box'][3]/li[4]/span[@class='label-val']/text()"})     #' ä¾›æš–æ–¹å¼',
        dict.update({'power_supply'  :".//ul[@class='x-box'][3]/li[6]/span[@class='label-val']/text()"})  #'ä¾›ç”µæ–¹å¼',
        dict.update({'open_date':".//ul[@class='x-box'][2]/li[@class='all-row'][3]/span[@class='label-val']/text()"}) #å¼€ç›˜æ—¶é—´
        return  dict
    def get_house_info(self):
        # è¯»å–æ•°æ®åº“
        sql = 'select * from DB_HOUSE_PRICES.house_item'
        house_info = pd.read_sql_query(sql=sql, con=self.conn)
        return house_info

    def get_buildings_BaseInfo(self, min_page_number, max_page_number):
        '''
        1ã€å¦‚æœ‰æ–°å¢æ¥¼ç›˜ï¼Œå¢é‡å†™å…¥
        2ã€å¦‚æœæœ‰æ¥¼ç›˜åç§°å­˜åœ¨ï¼Œåˆ™ä¸å¤„ç†
        :param min_page_number:
        :param max_page_number:
        :return:
        '''
        xpath_bds=self.get_xpathRds() #è·å–xpath
        for page_number in range(min_page_number, max_page_number + 1):
            one_url = self.one_url.format(page_number=page_number)
            one_url_list = self.get_List(one_url, self.headers, self.re_bds_url)
            one_zone_list = self.get_List(one_url, self.headers, xpath_bds.get('zone'))

            for i in range(0, len(one_url_list)):
                # è·å–æ¥¼ç›˜é¡µé¢ä¿¡æ¯
                two_url = self.prefix_url + one_url_list[i]
                html1 = requests.get(url=two_url, headers=self.headers).text
                parse_html = etree.HTML(html1)
                t_name = self.get_realValue(parse_html,xpath_bds.get( 'name'))  # æ¥¼ç›˜å
                t_house_type = self.get_realValue(parse_html, xpath_bds.get('house_type'))  # æˆ¿å±‹ç±»å‹ ä½å®… å•†ç”¨ å•†ä½ä¸¤ç”¨

                # æŸ¥è¯¢æ¥¼ç›˜ä¹‹å‰æ˜¯å¦è®°å½•è¿‡
                flag = self.sql_query(column_list=['house_name', 'house_type'], value_list=[t_name, t_house_type])
                if flag.empty:
                    t_other_name = self.get_realValue(parse_html, xpath_bds.get('other_name'))  # åˆ«å
                    t_other_name = t_other_name.replace('åˆ«åï¼š', '')
                    # t_price= parse_html.xpath(price) #å•ä»·
                    t_sale_status = self.get_realValue(parse_html, xpath_bds.get('tag_item'))  # æ˜¯å¦åœ¨å”®
                    t_address = self.get_realValue(parse_html,xpath_bds.get('address') )  # åœ°å€
                    t_new_open_date = self.get_realValue(parse_html, xpath_bds.get('new_open_date'))  # æœ€æ–°å¼€ç›˜
                    if t_new_open_date == '':
                        t_new_open_date = self.get_realValue(parse_html,
                                                             ".//div[@class='resblock-info animation qr-fixed post_ulog_exposure_scroll']/div[@class='info-wrap']/div[@class='middle-info animation']/ul[@class='info-list']/li[@class='info-item'][2]/span[@class='content']/text()")
                    t_rooms = parse_html.xpath(xpath_bds.get('rooms'))  # å‡ å®¤
                    house_zone = one_zone_list[i].strip()
                    # è·å–"æ›´å¤š"è¯¦æƒ…é¡µ
                    html = requests.get(url=two_url + "xiangqing/", headers=self.headers).text
                    parse_html = etree.HTML(html)
                    t_feature = self.get_realValue(parse_html, xpath_bds.get('feature'))  # ç‰¹è‰²æè¿°ï¼šæˆç†Ÿå•†åœˆ å“ç‰Œæˆ¿ä¼ VRçœ‹æˆ¿ ç»¿åŒ–ç‡é«˜
                    t_builders = self.get_realValue(parse_html, xpath_bds.get('builders'))  # å¼€å‘å•†

                    # æ‹¼å­—æ®µæˆä¸€ä¸ªå­—å…¸ï¼Œæ–¹ä¾¿å†™å…¥
                    dict = {}
                    dict.update({'house_name': t_name})
                    dict.update({'collecting_time': collecting_time})
                    dict.update({'other_name': t_other_name})
                    dict.update({'house_zone': house_zone})
                    dict.update({'sale_status': t_sale_status})
                    dict.update({'house_type': t_house_type})
                    dict.update({'address': t_address})
                    # dict.update({'new_open_date':t_new_open_date})
                    # è½¬æ¢roomsä¸ºå­—ç¬¦ä¸²
                    dict.update({'rooms': ','.join(t_rooms) if t_rooms else ''})
                    dict.update({'features': t_feature})
                    dict.update({'builders': t_builders})
                    dict.update({'url_source': two_url})  # urlåœ°å€
                    dict.update({'house_id': str(uuid.uuid1()).replace('-', '')})
                    # dataframe = pd.DataFrame(dict, index=[0])
                    dataframe=pd.DataFrame.from_dict(dict,orient='index').T
                    dataframe.to_sql('house_item', self.conn, if_exists='append', index=False)
                    print('{} â€”Sucessï¼**é¡µé¢={}'.format(t_name, page_number))
                else:
                    print('{} â€”â€”â€”â€”å·²ç»å­˜åœ¨ï¼Œç›´æ¥è·³è¿‡ï¼ŒçŠ¶æ€ï¼špassï¼**é¡µé¢={}'.format(t_name,page_number))
                time.sleep(random.randint(1, 2))

            print('*********ç¬¬{d}ä¸ªé¡µé¢*****over******è·å–å®Œæˆï¼\n'.format(d=page_number))
    def write_house_price(self):
        #è¯»å–æ•°æ®åº“
        house_info=self.get_house_info()
        #è·å–xpath
        xpath_dict=g=self.get_xpathRds()
        for index, row in house_info[419:].iterrows():
            id=row['house_id']
            name=row['house_name']
            url=row['url_source']
            html_content = requests.get(url=url, headers=self.headers).text
            parse_html = etree.HTML(html_content)

            # å¼€å§‹æå–æ•°æ®ï¼Œå…ˆæå–urlçš„æ•°æ®ï¼Œæ”¾å…¥house_priceè¡¨ä¸­
            dict = {}
            dict.update({'mark_labe': 0})  # 0 åœ¨å”®æ¥¼ç›˜ä»·æ ¼ 1 äºŒæ‰‹æˆ¿ä»·æ ¼
            dict.update({'house_id': id})
            dict.update({'house_name': name})
            dict.update({'update_time': datetime.date.today()})
            # åˆ¤æ–­å½“å‰æ•°æ®æ˜¯å¦å·²ç»é‡‡é›†ï¼Œå¦‚æœæœ‰åˆ™passï¼Œå¦åˆ™å†™å…¥æ•°æ®
            sql = '''
                    select * 
                    from DB_HOUSE_PRICES.house_price
                    where house_id = "{id}" 
                    and mark_labe="{mark_labe}"
                    and update_time="{update_time}"
                    '''\
                .format(id=id,
                        mark_labe=dict.get('mark_labe'),
                        update_time=dict.get('update_time')
                        )
            df_temp = pd.read_sql_query(sql=sql, con=self.conn)
            flag=df_temp.empty
            if  df_temp.empty:
                price_list=self.get_List(m_url=url,headers=self.headers,re_bds=xpath_dict.get('price'))
                if not price_list:
                    pass
                elif len(price_list)==4:
                    dict.update({'price': price_list[0]})
                    dict.update({'unit': price_list[1]})
                    dict.update({'value': price_list[2]})
                    dict.update({'value_unit': price_list[1]})
                elif len(price_list)==2:
                    dict.update({'price': price_list[0]})
                    dict.update({'unit': price_list[1]})
                dataframe=pd.DataFrame.from_dict(dict,orient='index').T
                # print(dataframe)
                dataframe.to_sql('house_price', self.conn, if_exists='append', index=False)
                print(name,'å†™å…¥sucess!index=',index)
            else: print(name,' :å½“å‰å·²ç»é‡‡é›†ï¼passï¼index=',index)
            time.sleep(random.randint(1, 3))
    def write_house_info(self):
        '''
        å†™å…¥æ¥¼ç›˜è¯¦æƒ…ã€‚
        æ•°æ®è¡¨ï¼šhouser_info
        :return:
        '''
        house_info=self.get_house_info()
        # éå† DataFrame ä¸­çš„æ¯ä¸€è¡Œæ•°æ®
        for index, row in house_info[1167:].iterrows():
            id=row['house_id']
            name=row['house_name']
            url=row['url_source']+'xiangqing'
            html_content = requests.get(url=url, headers=self.headers).text
            parse_html = etree.HTML(html_content)
            # å¼€å§‹æå–æ•°æ®ï¼Œå…ˆæå–urlçš„æ•°æ®ï¼Œæ”¾å…¥house_priceè¡¨ä¸­
            dict = {}
            dict.update({'house_id': id})
            dict.update({'house_name': name})
            dict.update({'update_time': datetime.date.today()})
            # åˆ¤æ–­å½“å‰æ•°æ®æ˜¯å¦å·²ç»é‡‡é›†ï¼Œå¦‚æœæœ‰åˆ™passï¼Œå¦åˆ™å†™å…¥æ•°æ®
            sql = '''select house_id,house_name from DB_HOUSE_PRICES.house_info where house_id = "{id}" '''\
                .format(id=id)
            #ç”Ÿæˆè¯¦æƒ…é¡µé¢çš„xpath
            xpath = self.get_xpathRds_info_page()
            #ä»æ•°æ®åº“è·å–æ¥¼ç›˜çš„åŸºæœ¬ä¿¡æ¯ï¼Œå¦‚æœ‰å·²ç»å­˜åœ¨é‚£å°±è¿”å›æ•°æ®ï¼Œå¦åˆ™ä¸ºç©º
            df_temp = pd.read_sql_query(sql=sql, con=self.conn)
            #åˆ¤æ–­æ•°æ®æ˜¯å¦å­˜åœ¨
            if  df_temp.empty:
                for key , value in xpath.items():
                    # print(key, value)
                    str=self.get_realValue(parse_html=parse_html,xpath_bds=value)
                    dict.update({key: str})
                dataframe=pd.DataFrame.from_dict(dict,orient='index').T
                # print(dataframe)
                dataframe.to_sql('house_info', self.conn, if_exists='append', index=False)
                print(name,'å†™å…¥sucess!,index=',index)
            else: print(name,' :info å½“å‰å·²ç»é‡‡é›†ï¼passï¼index=',index)
            time.sleep(random.randint(1, 2))


    def run(self,min_page_number, max_page_number):

        self.write_house_price()
        # self.write_house_info()

# ä¸»å‡½æ•°
if __name__ == '__main__':

    # éœ€è¦çˆ¬å–ç½‘é¡µçš„èŒƒå›´
    min_page_number = 1  # ä»å½“å‰é¡µå¼€å§‹é‡‡é›†
    max_page_number = 8 # ç»ˆæ­¢é¡µé¢ï¼Œé‡‡é›†æ•°æ®åŒ…æ‹¬å½“å‰é¡µã€‚ğŸ“¢

    try:
        spider = housing_Prices_Spider()
        spider.run(min_page_number, max_page_number)
    except Exception as e:
        print(e)
